name: 'LLM Action'
description: 'GitHub Action to interact with OpenAI Compatible LLM services'
author: 'appleboy'

branding:
  icon: 'message-square'
  color: 'blue'

inputs:
  base_url:
    description: 'Base URL for OpenAI Compatible API endpoint'
    required: false
    default: 'https://api.openai.com/v1'
  api_key:
    description: 'API Key for authentication'
    required: true
  model:
    description: 'Model name to use'
    required: false
    default: 'gpt-4o'
  skip_ssl_verify:
    description: 'Skip SSL certificate verification'
    required: false
    default: 'false'
  system_prompt:
    description: 'System prompt to set the context. Supports plain text, file path, or URL (http://, https://). For files, use absolute/relative path or file:// prefix. Supports Go templates with environment variables (e.g., {{.GITHUB_REPOSITORY}}, {{.MODEL}}).'
    required: false
    default: ''
  input_prompt:
    description: 'User input prompt for the LLM. Supports plain text, file path, or URL (http://, https://). For files, use absolute/relative path or file:// prefix. Supports Go templates with environment variables (e.g., {{.GITHUB_REPOSITORY}}, {{.MODEL}}).'
    required: true
  temperature:
    description: 'Temperature for response randomness (0.0-2.0)'
    required: false
    default: '0.7'
  max_tokens:
    description: 'Maximum tokens in the response'
    required: false
    default: '1000'
  tool_schema:
    description: 'JSON schema for structured output via function calling. Supports plain text, file path, or URL. Supports Go templates with environment variables (e.g., {{.GITHUB_REPOSITORY}}).'
    required: false
    default: ''
  debug:
    description: 'Enable debug mode to print all parameters'
    required: false
    default: 'false'
  headers:
    description: 'Custom HTTP headers to include in API requests. Format: "Header1:Value1,Header2:Value2" or multiline with one header per line. Useful for log analysis or custom authentication.'
    required: false
    default: ''

outputs:
  response:
    description: 'The response from the LLM'

runs:
  using: 'docker'
  image: 'Dockerfile'
